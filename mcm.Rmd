# Metropolis-Hastings algorithm

We begin by defining the target probability density function.
The objective is to generate samples from a Laplace distribution centered at zero with scale parameter equal to 1.

The density function is:

$$ f(x)=\frac{1}{2} exp(-|x|) $$

We implement this density in R as follows:

```r
# Define the distribution function f(x)
f <- function(x) {
  0.5 * exp(-abs(x))
}


# Define the random walk Metropolis algorithm
random_walk_metropolis <- function(x0, N, s, f) {
  # Set up the vector to hold sample data
  samples <- numeric(N)
  # Assign the initial value to the first position of the vector holding the sampling results.
  samples[1] <- x0
  # Loop through the number of iterations N
  for (i in 2:N) {
    # Generate a candidate x_selected from the Normal distribution
    x_selected <- rnorm(1, mean = samples[i-1], sd = s)
    # Skip this loop if x_selected is NA not available to prevent empty
    if (is.na(x_selected)) {
      next
    }
    # Calculate the log acceptance ratio
    log_r <- log(f(x_selected)) - log(f(samples[i-1]))
    # Generate a random number from a uniform distribution
    rn <- runif(1)
#    as default min = 0, max = 1
#    rn <- runif(1, min = 0, max = 1)

    # Compare log of uniform random to log acceptance ratio
    if (log(rn) < log_r) {
      # Accept the new sample
      samples[i] <- x_selected
    } else {
      # Reject the new sample
      samples[i] <- samples[i-1]
    }
  }
  return(samples)
}
````


Simulate random numbers for the distribution with probability density function $f(x)=\frac{1}{2} exp(-|x|)$ which `abs(x)` is the absolute value of $x$ and `exp(x)` function is used to compute the exponential of $x$ with base $e$ which is $e^x$. in R we just input `f <- function(x) {  0.5 * exp(-abs(x))}` which let `f` to denote whole function.

> **Step 1:** Set up an initial value $x_0$  as well as a positive integer $N$ and a positive real number $s$.
```r
# Part 1a
# Parameters for initial value, sample size, and standard deviation
x0 <- 0
N <- 10000
s <- 1

```

In R, unlike in some statically typed languages such as C, it is **not** necessary to declare the type of variables in advance. R automatically determines the type of the variables based on the assigned values. Can directly assign values to and use variables. 

Therefore, we directly define `random_walk_metropolis` we need 3 values which is an initial value $x_0$ , positive integer $N$ and a positive real number $s$ and 1 function `f` from above, Function Definition as `random_walk_metropolis <- function(x0, N, s, f)`

In this function, initialize a numeric vector of **length** of the $N$ with `samples <- numeric(N)` to store sample data generated by the algorithm

Assigns the **initial value** by $x0$ to the *first element* of the vector `samples[1] <- x0` acting as the *starting point* for the entire sequence of samples. 

> **Step 2** Repeat the following procedure for $i = 1, \dots, N$ .
```r


# Generate samples
samples <- random_walk_metropolis(x0, N, s, f)

# Calculate and display Mean and Standard Deviation of the samples
sample_mean <- mean(samples)
sample_sd <- sd(samples)

# Console display Mean and Standard Deviation as required by the topic
cat(" Monte Carlo estimates Mean:", sample_mean, "\n")
cat(" Monte Carlo estimates Standard Deviation:", sample_sd, "\n")

# estimate the PDF data using kernel density estimation 
density_estimate <- density(samples)

```
Then need a repeatedly executing a block of code with $N$ times which is length of samples, from $2$ to $N$  write as `for (i in 2:N)` .Since the first sample value $samples[1]$ has already been initialized to $x_0$, the loop starts from 2 to end of last $sample[N]$ 

The `rnorm()` function is used to generate random numbers from a normal distribution:

> - Simulate a *random number* $x_‚àó$ from the *normal distribution* with mean $x_{i‚àí1}$ and *standard deviation* $s$

That should be `rnorm(1, mean = samples[i-1], sd = s)`which

- `1` indicates that **One Sample** is being generated.
 - `mean = samples[i-1] ` is the **Mean** of the random number generated should be the *previous sample value* from the vector samples.
- `sd = s` sets the **Standard Deviation** to $s$

And then we put this outcomes into `x_selected` to wait decision.

In the *Random Walk Metropolis* algorithm, if the candidate sample value is $NA$, this value to calculate the acceptance ratio would fail or erroneous outcomes. `if (is.na(x_selected)) { next }is` intended to handle potential NA (Not Available) values, if NA happended just use `NEXT` skip whis loop. This is intended to prevent **errors**. Although I have declared a seed before, there are currently no NA values was in this case. 

> - Compute the ratio: $$r(x_*, x_{i-1}) = \frac{f(x_*)}{f(x_{i-1})}$$


So as my work should be:

$$r(x_{\text{selected}}, x_{i-1}) = \frac{f(x_{\text{selected}})}{f(x_{i-1})}$$
Which the ratio of the *probability density functions* evaluated at the new candidate point $x_{selected}$ **devided** the previous point $x_{i-1}$. 

But after my attempt, I realized that there are practice tips at the bottom of the first page: 

> **Practical tip:** To avoid numerical errors, it is better to use the equivalent criterion $$\log u < \log r(x_*, x_{i-1}) = \log f(x_*) - \log f(x_{i-1})$$ 

So back to my work should be: $$\log(r(x_{\text{selected}}, x_{i-1})) = \log(f(x_{\text{selected}})) - \log(f(x_{i-1}))$$ so that should be in R code with `log_r <- log(f(x_selected)) - log(f(samples[i-1]))` which `log_r` is judge condition $r(x_*, x_{i-1})$ in later.

> - Generate a random number $u$ from the uniform distribution between $0$ and $1$.

the code `rn <- runif(1)` is firstly to generate a random number from a uniform distribution. Which will produces a single random number between $0$ and $1$, which is then assigned to the variable `rn`. 

> - if $u<r(x_*,x_{i-1})$ ,set $x_i=x_*$ , else set $x_i=x_{i-1}$ but in **Practical tip** instend of $\log u < \log r(x_*, x_{i-1})$ 

so that use `log(rn) < log_r` to judge is accept or not. If follow inequality just accept selected sample with $x_i = x_‚àó$ in R format  `samples[i] <- x_selected` to assigned into sample. Elsewhere, reject sample `samples[i] <- samples[i-1]` represent $x_i = x_{i‚àí1}$

End in define this function with return samples.

## Part 1(a) 

>  Apply the *random walk Metropolis algorithm* using $N=10000$ and $s=1$. Use the generated samples $(x_1,...x_N)$ *...to continue...*

So we set parameter with `N <- 10000` as $N=10000$ and `s <- 1` as $s=1$ . In here as **no** *initial value* $x_0$ is given and prevent errors so just choose be $zero$ as `x0 <- 0`

We need the function just defined above to generate samples `samples <- random_walk_metropolis(x0, N, s, f)`

> *...continue...* Construct a histogram and a kernel density plot in the same figure. Note that these provide estimates of $f(x)$.Over lay a graph of $f(x)$ on this figure to visualise the quality of these estimates.*...to continue...*

Also we need density estimate later for plotting `density_estimate <- density(samples)`

I plotting with 2 ways one is use Rtools lines and curve function as

```r
lines(density_estimate,col = "#3d00a8",lwd = 2)
curve(f,from = -10,to = 10,add = TRUE,col = "red",lty = 3,lwd = 2)
legend("topright",legend = c("Histogram","Kernel Density","True Density"),col = c("grey","#3d00a8","red"), lwd = 1, bty = "n")
grid(nx = NULL, ny = NULL, col = "gray", lty = "dotted")
```
which the <span style="color: #3d00a8;">Blue line</span> is <span style="color: #3d00a8;">**Kernel Density**</span> and <span style="color: red;">Red dotted lines</span> is 
which is <span style="color: red;">**True Density**</span>. <span style="color: grey;">**Histogram**</span> is in grey. 

> *...continue...* Also, report the sample mean
 andstandard deviation of the generated samples which  also known as the *Monte Carlo estimates* of the mean and standard deviation respectively

Calculate Mean and Standard Deviation of the samples use R tools with `sample_mean <- mean(samples)` and `sample_sd <- sd(samples)` and then we print it out in console `cat(" Monte Carlo estimates Mean:", sample_mean, "\n")` and `cat(" Monte Carlo estimates Standard Deviation:", sample_sd, "\n")`

## Part 1(b)
In the deployment of the random walk Metropolis-Hastings method (part of Markov Chain Monte Carlo techniques), section 1a presupposes the convergence of the algorithm. This implies that the algorithm, after numerous iterations, has adequately neared the intended distribution. So part 1b is required to validate this convergence

> (*using LaTeX*) Generate multiple sequences of \(x_0, \dots, x_N\), potentially using different initial values \(x_0\). Denote each of these sequences, also known as chains, by \(x_0^{(j)}, x_1^{(j)}, \dots, x_N^{(j)}\) for \(j = 1, 2, \dots, J\). 

```r

# Part 1b
# Assume want to generate multiple chains
generate_chains <- function(initial_values, N, s, f) {
  chains <- list()
  for (initial_value in initial_values) {
    # Generate a complete chain for each initial value using the Metropolis-Hastings function
    chains[[length(chains) + 1]] <- random_walk_metropolis(initial_value, N, s, f)
  }
  return(chains)
}

```


Need to define a function named `generate_chains`. This function is used in simulating *stochastic* processes, with the purpose of generating *multiple Markov chains*, each starting from a given $initial\ value$. The number  of elements $N$ each chain should contain.`generate_chains <- function(xi, N) ` Create an empty list named `chains` to store all the generated chains.`chains <- list()` Loop through the initial values `for (value in xi)`, creating a numeric vector chain of length $N$, where the *first* element is set to the current initial value. Here `chains[[length(chains) + 1]]` is a way to append the new chain at the end of the list chains. This syntax ensures that each new chain is stored sequentially in the list.
Define the vector of initial values `xi`, which will be used as the *starting points* for generating the various Markov chains. These initial values are $-2, 0, 2, 4$. Alternatively, generate four random initial values uniformly distributed within the range `[-10, 10]`.
```r

# Define initial values xi and generate chains
xi <- c(-2, 0, 2, 4)
#xi <- runif(4, min = -10, max = 10)
N <- 1000
s <- 0.001
chains <- generate_chains(xi, N, s, f)


calculate_R_hat <- function(chains, f) {
  J <- length(chains)
  Mj <- numeric(J)
  Vj <- numeric(J)
  
  for (j in seq_along(chains)) {
    chain <- chains[[j]]
    n <- length(chain)
    Mj[j] <- mean(chain)
    Vj[j] <- mean((chain - Mj[j])^2)
  }
  
  W <- mean(Vj)
  M <- mean(Mj)
  B <- mean((Mj - M)^2)
  
  R_hat <- sqrt((B + W) / W)
  return(R_hat)
}

```

### Calculate \( \hat{R} \) using the generated chains in each element

Firstly, $J$ stores the total number of chains contained in the chains list with `J <- length(chains)`. A numeric vector `Mj <- numeric(J)` is created with a length of $J$ for $Mj$, where all elements are initially set to $zero$. Similarly, a numeric vector `Vj` of also length $J$ is defined to store the sample variance for each chain as `Vj <- numeric(J)`

> - Define and compute \(M_j\) as the sample mean of chain \(j\) as:\[M_j = \frac{1}{N} \sum_{i=1}^{N} x_i^{(j)} \]

 These averages are stored in the vector `Mj`with `Mj[j] <- mean(chain)`

The variance is calculated by first computing the square of the difference between each element and the mean of its chain, and then taking the average of these squared differences. 

> - \(V_j\) as the within sample variance of chain \(j\) as: \[V_j = \frac{1}{N} \sum_{i=1}^{N} (x_i^{(j)} - M_j)^2 \]

The calculated variances are stored in the vector `Vj`. with `Vj[j] <- mean((chain - Mj[j])^2)`



>  Define and compute the overall within sample variance $W$ as
    \[
    W = \frac{1}{J} \sum_{j=1}^{J} V_j
    \]

Calculate the variance 
$ùëâ_J$  for each chain, where $j$ represents the chain index, and there are a total of $J$ chains.Take the average of the variances across all chains, `W <- mean(Vj)`which means summing up all $V_j$ values and then dividing by the number of chains $J$.

> Define and compute the overall sample mean $M$ as
    \[ 
    M = \frac{1}{J} \sum_{j=1}^{J} M_j,
    \]


\( M_j \), where \( j \) represents the \( j \)-th chain, and there are a total of \( J \) chains.`M <- mean(Mj)`Compute the average of all chain means by summing all \( M_j \) values and then dividing by the total number of chains \( J \).

> And the between sample variance $B$ as
    \[
    B = \frac{1}{J} \sum_{j=1}^{J} (M_j - M)^2
    \]

B is the variance between the means of all chains. It is calculated by taking the average of the squared deviations of each chain's mean from the overall mean, `B <- mean((Mj - M)^2)`which means summing all \( (M_j - M)^2 \) values and then dividing by the total number of chains \( J \).

The square root of the sum of between-chain variance and within-chain variance divided by the within-chain variance 

>   \[ 
    \hat{R} = \sqrt{\frac{B + W}{W}}
    \]


Generates multiple chains and Computes the \( \hat{R} \)  value based on the generated chains `chains <- generate_chains(xi, N, s, f) ` and `R_hat_value <- calculate_R_hat(chains, f)` to determine whether the chains have converged.

### Question required

> In general, values of \( \hat{R} \) close to $1$ indicate convergence, and it is usually desired for \( \hat{R} \) to be lower than $1.05$. Calculate the \( \hat{R} \) for the random walk Metropolis algorithm with $N =2000$, $s = 0.001$ and $J = 4$. 

```r

# Use the chains generated from generate_chains function
chains <- generate_chains(xi, N, s, f)
R_hat_value <- calculate_R_hat(chains, f)



N <- 2000
s <- 0
J <- 4
```
Generates initial values with defined four values for repeatedly result display of course work.
```R
x0_values <- c(-2, 0, 2, 4)
x0_values <- runif(4, min = -10, max = 10)
```

But also random number can be initial.

> Keeping $N$ and $J$ fixed, provide a plot of the values of \( \hat{R} \) a grid of s values in the interval between $0.001$ and $1$.

So plotting the sample with polt point and grid.
```r
plot(s_values, R_hat_values, type = 'b', col = 'purple', bg = par("bg"),pch = 20,main = "Plot of R-hat values in S values",xlab = "s values", ylab,"R-hat values",ylim = c(0.99,1.08),lwd = 2)
grid(nx = NULL, ny = NULL, col = "gray", lty = "dotted")
```

After plotting, we need to proof convergence as is apporaching value of $1$, so add a horizontal line in plotting

```r
abline(h = 1.05, col = 'red', lwd = 2, lty = 3)
abline(h = 1, col = 'darkred', lwd = 1.5 , lty =3)
```

